{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///\n",
      "\u001b[31mERROR: file:/// does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/robodiff/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing.managers import SharedMemoryManager\n",
    "import click\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import dill\n",
    "import hydra\n",
    "import pathlib\n",
    "import skvideo.io\n",
    "from omegaconf import OmegaConf\n",
    "import scipy.spatial.transform as st\n",
    "# from diffusion_policy.real_world.real_env import RealEnv\n",
    "# from diffusion_policy.real_world.spacemouse_shared_memory import Spacemouse\n",
    "from diffusion_policy.common.precise_sleep import precise_wait\n",
    "from diffusion_policy.real_world.real_inference_util import (\n",
    "    get_real_obs_resolution, \n",
    "    get_real_obs_dict)\n",
    "from diffusion_policy.common.pytorch_util import dict_apply\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.policy.base_image_policy import BaseImagePolicy\n",
    "from diffusion_policy.common.cv2_util import get_image_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(input, output, robot_ip, match_dataset, match_episode,\n",
    "    vis_camera_idx, init_joints, \n",
    "    steps_per_inference, max_duration,\n",
    "    frequency, command_latency):\n",
    "    # # load match_dataset\n",
    "    # match_camera_idx = 0\n",
    "    # episode_first_frame_map = dict()\n",
    "    # if match_dataset is not None:\n",
    "    #     match_dir = pathlib.Path(match_dataset)\n",
    "    #     match_video_dir = match_dir.joinpath('videos')\n",
    "    #     for vid_dir in match_video_dir.glob(\"*/\"):\n",
    "    #         episode_idx = int(vid_dir.stem)\n",
    "    #         match_video_path = vid_dir.joinpath(f'{match_camera_idx}.mp4')\n",
    "    #         if match_video_path.exists():\n",
    "    #             frames = skvideo.io.vread(\n",
    "    #                 str(match_video_path), num_frames=1)\n",
    "    #             episode_first_frame_map[episode_idx] = frames[0]\n",
    "    # print(f\"Loaded initial frame for {len(episode_first_frame_map)} episodes\")\n",
    "    \n",
    "    # load checkpoint\n",
    "    ckpt_path = input\n",
    "    payload = torch.load(open(ckpt_path, 'rb'), pickle_module=dill)\n",
    "    cfg = payload['cfg']\n",
    "    cls = hydra.utils.get_class(cfg._target_)\n",
    "    workspace = cls(cfg)\n",
    "    workspace: BaseWorkspace\n",
    "    workspace.load_payload(payload, exclude_keys=None, include_keys=None)\n",
    "    # hacks for method-specific setup.\n",
    "    action_offset = 0\n",
    "    delta_action = False\n",
    "    if 'diffusion' in cfg.name:\n",
    "        # diffusion model\n",
    "        policy: BaseImagePolicy\n",
    "        policy = workspace.model\n",
    "        if cfg.training.use_ema:\n",
    "            policy = workspace.ema_model\n",
    "        device = torch.device('cuda')\n",
    "        policy.eval().to(device)\n",
    "        # set inference params\n",
    "        policy.num_inference_steps = 16 # DDIM inference iterations\n",
    "        policy.n_action_steps = policy.horizon - policy.n_obs_steps + 1\n",
    "    elif 'robomimic' in cfg.name:\n",
    "        # BCRNN model\n",
    "        policy: BaseImagePolicy\n",
    "        policy = workspace.model\n",
    "        device = torch.device('cuda')\n",
    "        policy.eval().to(device)\n",
    "        # BCRNN always has action horizon of 1\n",
    "        steps_per_inference = 1\n",
    "        action_offset = cfg.n_latency_steps\n",
    "        delta_action = cfg.task.dataset.get('delta_action', False)\n",
    "    elif 'ibc' in cfg.name:\n",
    "        policy: BaseImagePolicy\n",
    "        policy = workspace.model\n",
    "        policy.pred_n_iter = 5\n",
    "        policy.pred_n_samples = 4096\n",
    "        device = torch.device('cuda')\n",
    "        policy.eval().to(device)\n",
    "        steps_per_inference = 1\n",
    "        action_offset = 1\n",
    "        delta_action = cfg.task.dataset.get('delta_action', False)\n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported policy type: \", cfg.name)\n",
    "    # setup experiment\n",
    "    dt = 1/frequency\n",
    "\n",
    "    obs_res = get_real_obs_resolution(cfg.task.shape_meta)\n",
    "    n_obs_steps = cfg.n_obs_steps\n",
    "    print(\"n_obs_steps: \", n_obs_steps)\n",
    "    print(\"steps_per_inference:\", steps_per_inference)\n",
    "    print(\"action_offset:\", action_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['agent_pos']\n",
      "using obs modality: rgb with keys: ['image']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n",
      "Diffusion params: 6.502567e+07\n",
      "Vision params: 1.119709e+07\n",
      "n_obs_steps:  2\n",
      "steps_per_inference: 6\n",
      "action_offset: 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(\n",
    "    input=\"/app/data/outputs/2024.09.22/07.35.36_train_diffusion_unet_hybrid_pusht_image/checkpoints/latest.ckpt\",\n",
    "    output=\"/app/data/outputs/2024.09.22/07.35.36_train_diffusion_unet_hybrid_pusht_image/checkpoints/output\",\n",
    "    robot_ip=\"192.168.0.204\",\n",
    "    match_dataset=None,\n",
    "    match_episode=None,\n",
    "    vis_camera_idx=0,\n",
    "    init_joints=False,\n",
    "    steps_per_inference=6,\n",
    "    max_duration=60,\n",
    "    frequency=10,\n",
    "    command_latency=0.01\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
